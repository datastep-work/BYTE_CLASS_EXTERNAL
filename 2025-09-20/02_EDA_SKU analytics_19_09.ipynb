{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "531dd27a",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "- This Python workbook demonstrating how to identify top-selling SKUs and perform 80-20 (Pareto) analysis to uncover business-critical insights using an FMCG retail sales dataset.\n",
    "- It covers file reading, data cleaning, Data Processing and sales analysis methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b97d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib\n",
    "# !pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe17847f",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "Step 1: Import necessary libraries for data manipulation and date operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6175501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import calendar\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0c54ef",
   "metadata": {},
   "source": [
    "### Data Loading and Exploration\n",
    "Step 2: Read the sales dataset (CSV file) into a pandas DataFrame\n",
    "\n",
    "- Data path - < Local Path>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54d184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file\n",
    "df = pd.read_csv(\"retail_sales_data_set1_2024.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba194b1",
   "metadata": {},
   "source": [
    "Step 3: Display the shape and column names to understand data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b116aeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of DataFrame (rows, columns)\n",
    "print(df.shape)\n",
    "\n",
    "# # Column names\n",
    "# print(df.columns)\n",
    "\n",
    "# Column names as a list\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa34994",
   "metadata": {},
   "source": [
    "Step 4: Preview the first few rows of the dataset for a quick check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27681bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1936d6",
   "metadata": {},
   "source": [
    "### Unique Values and Data Types\n",
    "Step 5: Find unique Item Names, and check numbers of unique items/departments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7416eaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Item_Name'].unique().tolist()\n",
    "df['Item_Name'].nunique(), df['Department'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31eaea1",
   "metadata": {},
   "source": [
    "Step 6: Check data types for each column to verify correct format before further processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586ed853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows column data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b44f11f",
   "metadata": {},
   "source": [
    "Step 7: Get detailed info including missing values and memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214e54c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  shows types along with non-null counts.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d842fd",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "Step 8: Convert date strings to datetime objects for easier date-based analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b828ad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sales_RealDate'] = pd.to_datetime(df['Sales_RealDate'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef64ab93",
   "metadata": {},
   "source": [
    "Step 9: Create new features - month, year, month labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c7fb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Month_of_purchase'] = df['Sales_RealDate'].dt.month\n",
    "df['Year_of_purchase'] = df['Sales_RealDate'].dt.year\n",
    "df['Month'] = df['Month_of_purchase'].apply(lambda x: calendar.month_abbr[x])\n",
    "df['Month_year'] = df.Year_of_purchase.map(str)+ \"-\" + df.Month.map(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3675a911",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60126c47",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "Step 10: Detect and handle missing values across all columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7168fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726fa672",
   "metadata": {},
   "source": [
    "Step 11: Fill missing Item Names and Department values and clean text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf6f196",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Calculating Total Amount\n",
    "df['Total_amount']= df['Unit_Price']* df['Quantity']\n",
    "\n",
    "### Filling missing values\n",
    "df['Item_Name'] = df['Item_Name'].replace(r'^\\s*$', np.nan, regex=True).fillna('UNKNOWN_ITEM')\n",
    "\n",
    "df['Item_Name'] = list(map (lambda x: (str(x).strip()).title(),df['Item_Name']))\n",
    "\n",
    "df['Department'] = list(map (lambda x: str(x).upper(),df['Department']))\n",
    "\n",
    "df['Bar_Code'] = list(map (lambda x: str(x).strip('.0'),df['Bar_Code']))\n",
    "\n",
    "df['Department'] = list(map (lambda x: \"UNKNOWN_DEPT\" if x=='NAN' else x,df['Department']))\n",
    "\n",
    "df.drop(df[(df['Unit_Price']==0)&(df['Total_amount']==0)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c39a0d",
   "metadata": {},
   "source": [
    "### Date Range Validation\n",
    "Step 12: Display earliest, latest, and range of transaction dates in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7b8a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Earliest date:\", df['Sales_RealDate'].min())\n",
    "print(\"Latest date:\", df['Sales_RealDate'].max())\n",
    "print(\"Date range:\", df['Sales_RealDate'].max() - df['Sales_RealDate'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c51bd2",
   "metadata": {},
   "source": [
    "# SKU analytics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ba41b9",
   "metadata": {},
   "source": [
    "1. Total Sales (Value & Volume)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a00cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value (Revenue)\n",
    "total_sales_value = df[\"Total_amount\"].sum()\n",
    "\n",
    "# Volume (Units sold)\n",
    "total_sales_volume = df[\"Quantity\"].sum()\n",
    "\n",
    "print(\"Total Sales Value:\", round(total_sales_value,2))\n",
    "print(\"Total Sales Volume:\", total_sales_volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88900abc",
   "metadata": {},
   "source": [
    "2. Sales per Department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289f2d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_by_department = df.groupby(\"Department\").agg({\n",
    "    \"Total_amount\": \"sum\",\n",
    "    \"Quantity\": \"sum\"\n",
    "}).reset_index()\n",
    "\n",
    "print(sales_by_department)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a10f5db",
   "metadata": {},
   "source": [
    "3. Average Selling Price (ASP)\n",
    "- ASP is Total Sales รท Quantity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32dbcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall ASP (Average Selling Price)\n",
    "asp_overall = df[\"Total_amount\"].sum() / df[\"Quantity\"].sum()\n",
    "\n",
    "# ASP per Item using groupby().agg() to avoid warnings\n",
    "asp_item = df.groupby(\"Item_Name\").agg({\n",
    "    \"Total_amount\": \"sum\",\n",
    "    \"Quantity\": \"sum\"\n",
    "}).assign(ASP=lambda x: x[\"Total_amount\"] / x[\"Quantity\"]).reset_index()\n",
    "\n",
    "# Keep only necessary columns\n",
    "asp_item = asp_item[[\"Item_Name\", \"ASP\"]]\n",
    "\n",
    "# Output\n",
    "print(\"Overall ASP:\", asp_overall)\n",
    "print(asp_item.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db265c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "asp_sorted = asp_item.sort_values(\"ASP\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47d3e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "### Top 10 SKUs (top 10 row from data) selected for Vizualization\n",
    "sns.barplot(x=\"Item_Name\", y=\"ASP\", data=asp_sorted.head(20))\n",
    "\n",
    "plt.title(\"Average Selling Price per SKU\", fontsize=14)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"Average Selling Price\")\n",
    "plt.xlabel(\"SKU\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71b3aab",
   "metadata": {},
   "source": [
    "4. Contribution to Total Sales (%)\n",
    "\n",
    "- How much each SKU/Item contributes to total sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d039ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total sales for denominator\n",
    "total_sales = df[\"Total_amount\"].sum()\n",
    "\n",
    "# Contribution per Item\n",
    "contribution_item = df.groupby(\"Item_Name\")[\"Total_amount\"].sum().reset_index()\n",
    "contribution_item[\"Contribution_%\"] = (contribution_item[\"Total_amount\"] / total_sales) * 100\n",
    "\n",
    "print(contribution_item.sort_values(\"Contribution_%\", ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6d67b6",
   "metadata": {},
   "source": [
    "5. Order Frequency per SKU\n",
    "- Number of distinct orders where SKU was present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433eb2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order frequency per SKU (unique invoices)\n",
    "order_freq = df.groupby(\"Item_Name\")[\"Invoice_id\"].nunique().reset_index()\n",
    "order_freq.rename(columns={\"Invoice_id\": \"Order_Frequency\"}, inplace=True)\n",
    "\n",
    "print(order_freq.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa6076a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f228cd9c",
   "metadata": {},
   "source": [
    "## Top SKUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412ae411",
   "metadata": {},
   "source": [
    "Step 13: Top SKUs/Items Based on Total Sales Amount ('Unit_Price' x 'Quantity')  and Total Quantity Sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc934434",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Group items and calculate total sales for each group\n",
    "item_table = df.groupby(['Item_Name'], as_index=False).agg(total_amount=('Total_amount', 'sum'))\n",
    "## Sort items by total sales amount in descending order to highlight top SKUs\n",
    "item_table = item_table.sort_values('total_amount',ascending=False).reset_index(drop=True)\n",
    "## Display the output table listing SKUs by total sales amount\n",
    "item_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6effa1",
   "metadata": {},
   "source": [
    "Bar Chart โ Total Sales (Value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d03151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "### Top 10 SKUs (top 10 row from data) selected for Vizualization\n",
    "sns.barplot(x=\"Item_Name\", y=\"total_amount\", data=item_table.sort_values(\"total_amount\", ascending=False)[:10])\n",
    "\n",
    "plt.title(\"Total Sales Value by SKU\", fontsize=14)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"Sales Value\")\n",
    "plt.xlabel(\"SKU\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb0f20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Group items and calculate total Quantity sold for each group\n",
    "item_table1 = df.groupby(['Item_Name'], as_index=False).agg(total_qty=('Quantity', 'sum'))\n",
    "## Sort items by total Quantity sold in descending order to highlight top SKUs\n",
    "item_table1 = item_table1.sort_values('total_qty',ascending=False).reset_index(drop=True)\n",
    "## Display the output table listing SKUs by total Quantity sold\n",
    "item_table1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b95e64",
   "metadata": {},
   "source": [
    "Bar Chart โ Total Sales (Volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd3368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "### Top 10 SKUs (top 10 row from data) selected for Vizualization\n",
    "sns.barplot(x=\"Item_Name\", y=\"total_qty\", data=item_table1.sort_values(\"total_qty\", ascending=False)[:10])\n",
    "\n",
    "plt.title(\"Total Sales Volume by SKU\", fontsize=14)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"Units Sold\")\n",
    "plt.xlabel(\"SKU\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2094fec8",
   "metadata": {},
   "source": [
    "### 80-20 Analysis and Grouping\n",
    "Step 14: Bucket items based on sales deciles for visualization and decision making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53b853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of group want to show in decile table \n",
    "group_number = 10\n",
    "\n",
    "## Creating decile groups \n",
    "data_cut = pd.DataFrame()\n",
    "data_cut['item'] = item_table['Item_Name']\n",
    "data_cut['amount'] = pd.to_numeric(item_table.total_amount)\n",
    "\n",
    "\n",
    "data_cut['bucket'] = pd.qcut(data_cut['amount'], group_number)\n",
    "grouped = data_cut.groupby('bucket', as_index = False,observed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aab1e5a",
   "metadata": {},
   "source": [
    "### Output Tables and Visuals\n",
    "Step 15: Generate cumulative summaries and display final tables for the decile analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8071a516",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create an empty DataFrame to hold the decile analysis summary statistics\n",
    "\n",
    "waterfall_table = pd.DataFrame()\n",
    "waterfall_table['Decile'] = [i for i in range (group_number, 0, -1)]\n",
    "\n",
    "# Populate it with calculated fields including decile number, minimum and maximum sales amounts, \n",
    "# total sales amount, and item count for each decile group as derived from the grouped data\n",
    "waterfall_table['min_amount'] = grouped.min()['amount']\n",
    "waterfall_table['max_amount'] = grouped.max()['amount']\n",
    "waterfall_table['tot_amount'] = grouped.sum()['amount']\n",
    "waterfall_table['item_count'] = grouped.count()['item']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90be8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 16: Sort each decile group in descending order by minimum item value \n",
    "waterfall_table = waterfall_table.sort_values(by=\"min_amount\", ascending=False).reset_index(drop = True)\n",
    "\n",
    "### Calculate cumulative total amount and cumulative count across the sorted decile groups\n",
    "waterfall_table['cumu_tot_amount'] = waterfall_table['tot_amount'].cumsum()\n",
    "waterfall_table['cumu_count'] = waterfall_table['item_count'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8685eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sort each decile group in descending order by minimum item value\n",
    "waterfall_table = waterfall_table.sort_values(by=\"min_amount\", ascending=False).reset_index(drop=True)  # Highest-value groups appear first for clearer cumulative trend analysis\n",
    "\n",
    "## Calculate the cumulative total amount across all groups, building a running sum for visualization\n",
    "waterfall_table['cumu_tot_amount'] = waterfall_table['tot_amount'].cumsum()  # Shows how total sales accumulate group by group\n",
    "\n",
    "## Calculate the running total count of items sold for each group, useful for 80-20 and Pareto analysis\n",
    "waterfall_table['cumu_count'] = waterfall_table['item_count'].cumsum()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdf2154",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 17: Calculate cumulative percentages of total amount and item count relative to their respective overall sums, \n",
    "### rounding to 2 and 0 decimal places for clarity in reporting\n",
    "waterfall_table['%cumu_tot_amount'] =  round((waterfall_table['cumu_tot_amount']/waterfall_table['tot_amount'].sum())*100,2)\n",
    "waterfall_table['%cumu_count'] =  round((waterfall_table['cumu_count']/waterfall_table['item_count'].sum())*100,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a621c8",
   "metadata": {},
   "source": [
    "Step 18: Extract key cumulative metrics from the waterfall table for summary display -\n",
    "count of items, cumulative percentage of total amount, and cumulative percentage of item count\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae5b130",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_table = waterfall_table[['Decile','cumu_count','%cumu_tot_amount','%cumu_count']]\n",
    "full_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82a1b07",
   "metadata": {},
   "source": [
    "Pareto (80-20) Line Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754213ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(6,6))\n",
    "\n",
    "# Bar chart for sales\n",
    "ax1.plot(full_table['Decile'], full_table[\"%cumu_count\"], color=\"darkblue\", marker=\"o\")\n",
    "ax1.set_ylabel(\"Cumulative % of Item Count\", color=\"darkblue\")\n",
    "\n",
    "# Cumulative % line (Pareto)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(full_table['Decile'], full_table[\"%cumu_tot_amount\"], color=\"red\", marker=\"o\")\n",
    "ax2.axhline(80, color=\"green\", linestyle=\"--\")  # 80% threshold line\n",
    "ax2.set_ylabel(\"Cumulative % of Total Sales Amount\", color=\"red\")\n",
    "\n",
    "# Add values on cumulative % points\n",
    "for i, val in enumerate(full_table[\"%cumu_tot_amount\"]):\n",
    "    ax2.text(i, val+1, f\"{val:.1f}%\", color=\"red\", fontsize=8, ha=\"left\")\n",
    "\n",
    "# Titles and formatting\n",
    "plt.title(\"Pareto (80-20) Analysis of SKU Sales\")\n",
    "ax1.set_xlabel(\"Decile\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060591d0",
   "metadata": {},
   "source": [
    "Step 19: Select the specified top group (e.g., top 2) from the waterfall summary table showing cumulative counts and percentages to analyze key contributors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd9a994",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_group = 2\n",
    "table = waterfall_table[['cumu_count','%cumu_tot_amount','%cumu_count']].iloc[top_group-1:top_group]\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0947665a",
   "metadata": {},
   "source": [
    "Step 20: This extracts the highest-ranked SKUs with their Total Sales Amount under the top group (e.g. 20 % cumulative count) selected above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058a2a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "toplist = item_table.iloc[:table['cumu_count'].iloc[0]]\n",
    "toplist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7f7e8a",
   "metadata": {},
   "source": [
    "### Item of the Month and Top Items\n",
    "Step : Identify top items per month and quarter for business insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b1a272",
   "metadata": {},
   "outputs": [],
   "source": [
    "## How many items to show in table\n",
    "top_items = 10\n",
    "\n",
    "df1 = df.groupby(['Year_of_purchase','Month_of_purchase','Month_year','Item_Name'], as_index=False).agg(total_sales = ('Total_amount', 'sum')).sort_values(by=\"total_sales\", ascending=False).reset_index(drop = True)\n",
    "\n",
    "# for top selling items \n",
    "df2 = df1.groupby([\"Year_of_purchase\",\"Month_of_purchase\",\"Month_year\"], as_index=False).nth(list(range(top_items)))\n",
    "top10 = df2.sort_values(by=[\"Year_of_purchase\",\"Month_of_purchase\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c9409d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e00855",
   "metadata": {},
   "source": [
    "### Conclusion and Learning Objectives\n",
    "- This workbook equips practical skills for retail data handling:\n",
    "- Reading and cleaning data sets with pandas\n",
    "- Feature engineering for time-based analysis\n",
    "- Identifying trends, top products, and seasonal effects in sales\n",
    "- Applying Pareto and decile analysis for inventory control\n",
    "- Experiment further with different groupings/filters to deepen insight!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5cc6ee",
   "metadata": {},
   "source": [
    "# End of Workbook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
